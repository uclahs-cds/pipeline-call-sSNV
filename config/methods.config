import nextflow.util.SysHelper

includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/schema/schema.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/retry/retry.config"

methods {
    set_process = {
        process.cache = params.cache_intermediate_pipeline_steps
    }

    // Function to ensure that resource requirements don't go beyond
    // a maximum limit
    check_max = { obj, type ->
        if (type == 'memory') {
            try {
                if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                    return params.max_memory as nextflow.util.MemoryUnit
                else
                    return obj
            } catch (all) {
                println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'time') {
            try {
                if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                    return params.max_time as nextflow.util.Duration
                else
                    return obj
            } catch (all) {
                println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'cpus') {
            try {
                return Math.min(obj, params.max_cpus as int)
            } catch (all) {
                println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
                return obj
            }
        }
    }

    set_resources_allocation = {
        def node_cpus = SysHelper.getAvailCpus()
        def node_memory_GB = SysHelper.getAvailMemory().toGiga()
        // Load base.config by default for all pipelines
        includeConfig "${projectDir}/config/base.config"
        if (params.ucla_cds) {
            if (node_cpus == 64) {
                // Check memory for M64 node
                if (node_memory_GB >= 950 && node_memory_GB <= 1010) {
                    includeConfig "${projectDir}/config/M64.config"
                } else {
                    throw new Exception("   ### ERROR ###   System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            } else {
                // Check memory for F series node
                if (node_memory_GB >= (node_cpus * 2 * 0.9 - 1) && node_memory_GB <= (node_cpus * 2)) {
                    includeConfig "${projectDir}/config/F${node_cpus}.config"
                } else {
                    throw new Exception("   ### ERROR ###   System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            }
        }
    }

    set_env = {
        if (params.ucla_cds) {
            /**
             * By default, if the /scratch directory exists, set it as the Nextflow working directory
             * If config file specified work_dir, set it as the Nextflow working directory
             *
             * WARNING: changing this directory can lead to high server latency and
             * potential disk space limitations. Change with caution! The 'workDir'
             * in Nextflow determines the location of intermediate and temporary files.
             */
            params.work_dir = (params.containsKey("work_dir") && params.work_dir) ? params.work_dir : "/scratch"
            schema.check_path(params.work_dir, 'w')
            workDir = params.work_dir
        } else {
            if (params.containsKey("work_dir") && params.work_dir) {
                schema.check_path(params.work_dir, 'w')
                workDir = params.work_dir
            } else {
                params.work_dir = "${launchDir}/work"
            }
        }
    }
    // Function to ensure that resource requirements don't go beyond
    // a maximum limit or below a minimum limit
    check_limits = { obj, type ->
        if (type == 'memory') {
            try {
                if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                    return params.max_memory as nextflow.util.MemoryUnit
                else if (obj.compareTo(params.min_memory as nextflow.util.MemoryUnit) == -1)
                    return params.min_memory as nextflow.util.MemoryUnit
                else
                    return obj
            } catch (all) {
                println "   ### WARNING ###   Max memory '${params.max_memory}' or min memory '${params.min_memory}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'time') {
            try {
                if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                    return params.max_time as nextflow.util.Duration
                else if (obj.compareTo(params.min_time as nextflow.util.Duration) == -1)
                    return params.min_time as nextflow.util.Duration
                else
                    return obj
            } catch (all) {
                println "   ### WARNING ###   Max time '${params.max_time}' or min time '${params.min_time}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'cpus') {
            try {
                return Math.max( Math.min( obj, params.max_cpus as int ), params.min_cpus as int )
            } catch (all) {
                println "   ### WARNING ###   Max cpus '${params.max_cpus}' or min cpus '${params.min_cpus}' is not valid! Using default value: $obj"
                return obj
            }
        }
    }

    set_sample_params = {
        params.multi_tumor_sample = false
        params.multi_normal_sample = false
        params.tumor_only_mode = false

        if (!params?['input']?['normal']?['BAM'] ) {
            params.tumor_only_mode = true
            params.input['normal'] = [id: 'Empty_id', BAM: "${params.work_dir}/NO_FILE.bam"]
        } else {
            if ( params.input['tumor'].size()  > 1 ) {
                params.multi_tumor_sample = true
            }
            if ( params.input['normal'].size() > 1 ) {
                params.multi_normal_sample = true
            }
        }

        if (params.multi_tumor_sample || params.multi_normal_sample) {
            params.sample_id = params.patient_id
        } else {
            params.sample_id = params.input['tumor'][0]['id']
        }
    }

    set_strelka2_params = {
        if (params.containsKey("call_region") && params.call_region) {
            params.use_call_region = true
        } else {
            params.call_region = "${params.work_dir}/NO_FILE.bed.gz"
            params.use_call_region = false
        }
        params.call_region_index = "${params.call_region}.tbi"
    }

    set_mutect2_params = {
        if (params.containsKey("germline_resource_gnomad_vcf") && params.germline_resource_gnomad_vcf) {
            params.germline = true
        } else {
            params.germline_resource_gnomad_vcf = "${params.work_dir}/NO_FILE.vcf.gz"
            params.germline = false
        }
        params.germline_resource_gnomad_vcf_index = "${params.germline_resource_gnomad_vcf}.tbi"
        // check if contamination estimation table exist and set params.use_contamination_estimation
        params.use_contamination_estimation = false
        if (params?["input"]?["tumor"]) {
            params.use_contamination_estimation = params["input"]["tumor"].any{
                t -> t.containsKey("contamination_table") && t["contamination_table"]
            }
        }

        if (!params.use_contamination_estimation) {
            for (tumor in params.input["tumor"]){
                tumor.contamination_table = "${params.work_dir}/NO_FILE.table"
            }
        }
    }

    set_output_directory = {
        def tz = TimeZone.getTimeZone("UTC")
        def date = new Date().format("yyyyMMdd'T'HHmmss'Z'", tz)
        params.output_dir = "${params.output_dir}/${manifest.name}-${manifest.version}/${params.sample_id}"
        params.log_output_dir = "${params.output_dir}/log-${manifest.name}-${manifest.version}-${date}"
    }
    set_pipeline_log = {
        trace.enabled = true
        trace.file = "${params.log_output_dir}/nextflow-log/trace.txt"

        timeline.enabled = true
        timeline.file = "${params.log_output_dir}/nextflow-log/timeline.html"

        report.enabled = true
        report.file = "${params.log_output_dir}/nextflow-log/report.html"
    }
    check_valid_algorithms = {
        Set valid_algorithms = ['somaticsniper', 'strelka2', 'mutect2', 'muse']
        if (params.tumor_only_mode || params.multi_tumor_sample || params.multi_normal_sample ) {
            valid_algorithms = ['mutect2']
        }
        for (algo in params.algorithm) {
            if (!(algo in valid_algorithms)) {
                if (params.tumor_only_mode) {
                    throw new Exception("ERROR: params.algorithm ${params.algorithm} contains an invalid value. Tumor-only mode or multi-sample mode is only applied to Mutect2 algorithm.")
                } else {
                    throw new Exception("ERROR: params.algorithm ${params.algorithm} contains an invalid value.")
                }
            }
        }
    }

    setup = {
        schema.load_custom_types("${projectDir}/config/custom_schema_types.config")
        schema.validate()
        methods.set_process()
        methods.set_resources_allocation()
        retry.setup_retry()
        methods.set_env()
        methods.set_sample_params()
        methods.set_strelka2_params()
        methods.set_mutect2_params()
        methods.set_output_directory()
        methods.set_pipeline_log()
        methods.check_valid_algorithms()
    }
}
